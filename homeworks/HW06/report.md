# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-04.csv`
- Размер: (25000, 62)
- Целевая переменная: `target` (содержит два класса: 0 и 1, доля: 0 - 95,08%, а 1 - 4,92%)
- Признаки: числовые

## 2. Protocol

- Разбиение: данные разделены на обучающую (train, 80% = 20 000 объектов) и тестовую (test, 20% = 5 000 объектов) выборки с использованием stratify=y для сохранения пропорций классов (95.08% / 4.92%) и random_state=42 для воспроизводимости.
- Подбор гиперпараметров: выполнялся исключительно на train с помощью GridSearchCV. Количество фолдов: 5 для всех моделей, кроме HistGradientBoostingClassifier (3 фолда для ускорения). Оптимизировалась метрика ROC-AUC, так как она устойчива к сильному дисбалансу классов (~95% vs ~5%).
- Метрики: 
* Accuracy — общая доля верных предсказаний (высока даже у Dummy, поэтому малоинформативна);
* F1-score — баланс precision и recall, фокусируется на редком классе (дефолт);
* ROC-AUC — основная метрика, оценивает способность модели ранжировать объекты по риску, не зависит от порога.
Эти метрики выбраны именно потому, что задача содержит сильный дисбаланс классов.

## 3. Models

Сравнивались следующие модели:

* DummyClassifier (strategy='most_frequent') — нулевая гипотеза, всегда предсказывает класс 0.
* LogisticRegression — baseline из S05, обучался в Pipeline со StandardScaler; подбирался параметр регуляризации C [0.01, 0.1, 1.0, 10.0, 100.0].
* DecisionTreeClassifier — подбирались max_depth [3, 5, 7, 10] и min_samples_leaf  [5, 10, 20, 50] для контроля переобучения.
* RandomForestClassifier — подбирались n_estimators=100, max_depth ∈ [5, 7, 10], min_samples_leaf  [5, 10] и max_features  [sqrt, log2].
* HistGradientBoostingClassifier — выбран как boosting-метод; подбирались max_iter [200, 300], learning_rate  [0.05, 0.1], max_depth  [4, 6] и min_samples_leaf [20, 50].

## 4. Results


| Модель                       | Accuracy | F1-score | ROC-AUC |
|------------------------------|----------|----------|---------|
| Dummy (most_frequent)        | 0.9508   | 0.0000   | 0.5000  |
| LogisticRegression           | 0.9622   | 0.4215   | 0.8380  |
| DecisionTree (tuned)         | 0.9600   | 0.5238   | 0.8251  |
| RandomForest (tuned)         | 0.9622   | 0.3762   | 0.8919  |
| HistGradientBoosting (tuned) | 0.9784   | 0.7259   | 0.9002  |


Победитель: HistGradientBoostingClassifier по всем метрикам, особенно по ROC-AUC (0.9002) и F1-score (0.7259). Это демонстрирует его превосходство в задачах с дисбалансом: он не только лучше ранжирует объекты, но и эффективнее выявляет редкий класс.

## 5. Analysis

- Устойчивость: при фиксированном random_state=42 результаты воспроизводимы. При изменении seed метрики могут колебаться на ±0.01–0.02, но порядок моделей остаётся стабильным: boosting > дерево > лес > логрег.
- Ошибки: confusion matrix для HistGradientBoosting показывает:
    * Высокая точность (precision) — большинство предсказанных дефолтов действительно являются дефолтами;
    * Хороший recall — модель находит ~72% всех реальных дефолтов (FN ≈ 28%);
    * Низкое число FP — мало ложных тревог.
    Это оптимальный баланс для задачи fraud detection.
- Интерпретация: permutation importance выявила ключевые признаки: f54, f25, f58, f38. Их перестановка снижает ROC-AUC на 0.01–0.021, что указывает на их высокую предсказательную силу. Это согласуется с EDA: у этих признаков наблюдаются смещённые распределения между классами. Признаки f43, f49 и другие имеют нулевую важность и могут быть удалены без потери качества.

## 6. Conclusion

1. Деревья решений легко переобучаются, но контроль через max_depth и min_samples_leaf эффективно ограничивает сложность и улучшает обобщающую способность.
2. Ансамбли значительно превосходят одиночные модели: Random Forest уменьшает дисперсию, а boosting (особенно HistGB) даёт наилучшее качество за счёт последовательного исправления ошибок.
3. При сильном дисбалансе accuracy вводит в заблуждение — необходимо использовать F1 и ROC-AUC, которые фокусируются на редком классе.
4. Честный ML-протокол (фиксированный train/test, CV только на train, один проход по test) критически важен для объективного сравнения моделей и избежания оптимистичных оценок.
5. Permutation importance — надёжный инструмент интерпретации, который помогает выявить действительно значимые признаки даже в "чёрном ящике" вроде градиентного бустинга.
6. HistGradientBoostingClassifier — современный и эффективный выбор для табличных данных с дисбалансом: он быстр, устойчив, требует меньше настройки и даёт высокое качество "из коробки".
