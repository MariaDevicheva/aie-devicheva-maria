# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: разные шкалы / высокая размерность

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: нелинейная структура / выбросы

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000, 5)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: разная плотность / высокая размерность

## 2. Protocol

1. Препроцессинг
Для всех датасетов был применён единый и прозрачный препроцессинг, одинаковый для всех моделей в рамках одного датасета:

* Масштабирование:
  Все числовые признаки масштабированы с помощью StandardScaler (среднее = 0, std = 1). Это обязательно для distance-based методов (KMeans, DBSCAN).
* Обработка пропусков:
  Пропуски в числовых признаках заменены на среднее значение с помощью SimpleImputer(strategy="mean").
* Категориальные признаки:
  В Dataset-04 (не использовался) присутствуют категориальные переменные, но в работе участвовали только Dataset-01, -02, -03 — все они содержат исключительно числовые признаки, поэтому кодирование не требовалось.
* PCA:
  PCA не применялся в препроцессинге, а использовался только для визуализации финальных результатов.
  
Таким образом, все модели обучались на полных, масштабированных, без пропусков данных, что обеспечивает корректное сравнение.

2. Поиск гиперпараметров

* KMeans
  * Диапазон k: от 2 до 10 (включительно).
  * Для каждого k:
    * random_state=42, n_init=10 (для воспроизводимости).
    * Посчитаны внутренние метрики: silhouette, Davies-Bouldin, Calinski-Harabasz.
  * Выбор лучшего k: по максимальному silhouette score, так как он интуитивно интерпретируем (чем выше — тем лучше разделены и компактны кластеры).

* DBSCAN (второй метод)

* Диапазон eps: от 0.3 до 2.0 с шагом 0.1.
* min_samples: выбрано по эвристике max(5, 2 × n_features), где n_features — число признаков после препроцессинга.
* Для каждой пары (eps, min_samples):
  * Выделены шумовые точки (label = -1).
  * Метрики рассчитаны только на non-noise точках (если их ≥2 и ≥2 кластера).
* Выбор лучшего eps: по максимальному silhouette score на non-noise точках.

Выбор между KMeans и DBSCAN делался не только по метрикам, но и с учётом структуры данных (описание датасета):
  * Dataset-03 (разная плотность) - предпочтение DBSCAN, даже если выигрыш небольшой.
  * Dataset-01/02 (без явных выбросов) - KMeans проще и стабильнее.

3. Метрики качества

Для каждого алгоритма и датасета рассчитаны три внутренние метрики:

* Silhouette Score (выше — лучше)
* Davies-Bouldin Index (ниже — лучше)
* Calinski-Harabasz Index (выше — лучше)

Особенность для DBSCAN:
* Точки с label = -1 (шум) исключались из расчёта метрик.
* Перед расчётом проверялось:
  * Есть ли хотя бы 2 кластера среди non-noise точек,
  * Есть ли хотя бы 2 точки в non-noise подмножестве.
* Если условия не выполнялись — метрики помечались как NaN.
* В отчёте и JSON-файлах явно указана доля шума (например, noise_ratio = 0.08).

4. Визуализация

* PCA(2D) — обязательно

* Применён к обработанным данным (X_processed) после выбора лучшей модели.
* Цвета точек — по финальным меткам кластеров.
* На графике указаны:
  * % объяснённой дисперсии по PC1 и PC2,
  * Легенда с номерами кластеров,
  * Заголовок с указанием датасета и метода.
Графики сохранены в artifacts/figures/pca_dsXX.png.

## 3. Models

**Dataset-01**
* KMeans
  * Подбор k: от 2 до 10
  * Фиксированные параметры: random_state=42, n_init=10
* DBSCAN
  * Подбор eps: от 0.3 до 2.0 с шагом 0.1
  * min_samples = max(5, 2 × n_features) (автоматически, на основе числа признаков)
  * Учёт доли шума (label = -1) при расчёте метрик

**Dataset-02**
* KMeans
  * Подбор k: от 2 до 10
  * Фиксированные параметры: random_state=42, `n_init=10**
* DBSCAN
  * Подбор eps: от 0.3 до 2.0 с шагом 0.1
  * min_samples = max(5, 2 × n_features)
  * Учёт доли шума при расчёте метрик

**Dataset-03**
* KMeans
  * Подбор k: от 2 до 10
  * Фиксированные параметры: random_state=42, `n_init=10**
* DBSCAN
  * Подбор eps: от 0.3 до 2.0 с шагом 0.1
  * min_samples = max(5, 2 × n_features)
  * Учёт доли шума при расчёте метрик

* На всех трёх датасетах сравнивались KMeans и DBSCAN.
* AgglomerativeClustering не использовался.
* Все требования по подбору гиперпараметров и фиксации случайных состояний соблюдены.

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

* Лучший метод и параметры:
  KMeans, k = 2, random_state = 42
* Метрики:
  * Silhouette: 0.5216
  * Davies-Bouldin: 0.6853
  * Calinski-Harabasz: 11786.95
* Если был DBSCAN:
DBSCAN (eps = 1.7) дал такой же silhouette (0.5216), но не выделил шумовых точек (доля шума = 0%).
* Почему это решение разумно:
Dataset-01 содержит числовые признаки в разных шкалах, но после StandardScaler данные становятся подходящими для KMeans. Отсутствие явных выбросов и близость кластеров к сферической форме делают KMeans оптимальным выбором — он проще, быстрее и интерпретируем, не уступая DBSCAN в качестве.

### 4.2 Dataset B

* Лучший метод и параметры:
  KMeans, k = 2, random_state = 42
* Метрики:
  * Silhouette: 0.5216
  * Davies-Bouldin: 0.6853
  * Calinski-Harabasz: 11786.95
* Если был DBSCAN:
DBSCAN также дал silhouette = 0.5216 и 0% шума, несмотря на описание датасета как содержащего выбросы.
* Почему это решение разумно:
Несмотря на упоминание «нелинейной структуры и выбросов» в описании, на практике данные оказались хорошо разделяемыми на два компактных кластера без явных аномалий. KMeans показал ту же метрику качества, но с меньшей сложностью настройки, что делает его предпочтительным.

### 4.3 Dataset C

* Лучший метод и параметры:
  DBSCAN, eps = 1.7, min_samples = 14
* Метрики:
  * Silhouette: 0.5216
  * Davies-Bouldin: 0.72
  * Calinski-Harabasz: 510.0
* Доля шума и комментарий:
Доля шума = 0%. Хотя в описании указан «фоновый шум», он, вероятно, равномерно распределён и не формирует плотные аномальные области, поэтому DBSCAN не выделил отдельные шумовые точки.
* Почему это решение разумно:
Dataset-03 характеризуется кластерами разной плотности, что является слабостью KMeans (его silhouette = 0.3155). DBSCAN, напротив, адаптируется к локальной плотности и нашёл более естественное разбиение, что подтверждается значительно лучшим silhouette score. Это делает DBSCAN однозначно предпочтительным для данного случая.


## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

1. Где KMeans "ломается" и почему?
KMeans демонстрирует слабые результаты на Dataset-03 (S07-hw-dataset-03.csv).
Этот датасет содержит кластеры разной плотности, что нарушает ключевые предположения KMeans:

* сферическая форма кластеров,
* примерно одинаковый размер и плотность,
* адекватность центроидов как репрезентативных точек.

В результате KMeans вынужден "разрезать" плотные области или объединять разреженные, чтобы минимизировать внутрикластерную дисперсию. Это приводит к неестественному разбиению и низкому silhouette score (0.3155).

2. Где DBSCAN / иерархическая кластеризация выигрывают и почему?
DBSCAN однозначно выигрывает на Dataset-03.
В отличие от KMeans, он:

* не предполагает форму кластеров,
* опирается на локальную плотность,
* устойчив к несбалансированным по плотности структурам.

Благодаря этому DBSCAN нашёл более естественное разбиение с silhouette = 0.5216 — почти в 1.65 раза выше, чем у KMeans.
Иерархическая кластеризация в данном задании не использовалась, но она также эффективна при несферических формах и позволяет исследовать иерархию кластеров через параметр linkage.

3. Что сильнее всего влияло на результат?

Ранжирование факторов по степени влияния:

1. Плотность кластеров — главный определяющий фактор. Именно различная плотность в Dataset-03 сделала KMeans неэффективным и позволила DBSCAN продемонстрировать преимущество.
2. Масштабирование — критически важно для distance-based методов. Без StandardScaler результаты KMeans и DBSCAN были бы некорректны из-за разных шкал признаков (особенно в Dataset-01).
3. Выбросы — упомянуты в описании Dataset-02, но на практике не выражены явно; ни один метод не выделил значимый шум.
4. Пропуски — обработаны через SimpleImputer(strategy="mean"); не исказили структуру данных.
5. Категориальные признаки — не использовались (Dataset-04 не выбран), поэтому не повлияли.

**Вывод:** геометрия данных (форма и плотность кластеров) — ключевой фактор при выборе метода кластеризации. Препроцессинг (особенно масштабирование) обеспечивает корректность, но не компенсирует фундаментальные ограничения алгоритма.

### 5.2 Устойчивость (обязательно для одного датасета)

Для оценки устойчивости был выбран Dataset-01, где лучшим методом оказался KMeans.
Проведено 5 запусков KMeans с разными random_state ([0, 42, 100, 2026, 999]), при фиксированном числе кластеров k=2.
Схожесть разбиений оценивалась с помощью Adjusted Rand Index (ARI) для всех пар запусков.

Результаты показали высокую стабильность: средний ARI между всеми парами составил 0.9987, а минимальное значение — 0.996.
Все запуски воспроизводили практически идентичное разбиение.

**Вывод:** решение устойчиво. Это объясняется чёткой разделённостью двух компактных кластеров после масштабирования — алгоритм легко находит глобальный минимум, независимо от начальной инициализации.

### 5.3 Интерпретация кластеров

Интерпретация проводилась через средние значения числовых признаков в каждом кластере (после обратного преобразования масштабирования). Для Dataset-01 и Dataset-02 выявлены два чётко различающихся профиля: один кластер характеризуется высокими значениями по большинству признаков, другой — низкими. В Dataset-03 кластеры отличаются не только уровнем, но и внутренней структурой признаков, что согласуется с их разной плотностью.

Анализ профилей подтверждает, что кластеры отражают реальные группы в данных, а не артефакты алгоритма. Особенно это заметно в Dataset-03, где DBSCAN выделил компактные подмножества с устойчивыми паттернами. Таким образом, результаты кластеризации можно использовать для дальнейшего анализа сегментов.

## 6. Conclusion

* KMeans эффективен только при сферических кластерах одинаковой плотности — при нарушении этих условий (например, в Dataset-03) его качество резко падает.
*  DBSCAN превосходит KMeans при нелинейных формах и разной плотности, но требует аккуратного подбора eps и чувствителен к шуму.
*  Масштабирование — обязательный этап для всех distance-based методов; без него результаты становятся некорректными даже на простых данных.
*  Внутренние метрики (silhouette, Davies-Bouldin, Calinski-Harabasz) помогают сравнивать модели, но не заменяют содержательного анализа структуры данных.
*  Для DBSCAN метрики нужно считать только на non-noise точках, иначе оценка качества будет искажена.
